{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ad67c5-ee5f-4d53-a027-405c67cc700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.use('agg')\n",
    "from matplotlib.figure import Figure\n",
    "import panel as pn\n",
    "import statistics\n",
    "import math\n",
    "import param\n",
    "import io\n",
    "import os\n",
    "from panel.viewable import Viewer\n",
    "from scipy import stats\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5b16b8-0983-4907-8eeb-afbcc72ad312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('/Users/ctlewis/U-Pb-LA-ICP-MS-Reduction/output_lasertramZ_one_010523_noc.xlsx',\n",
    "                         sheet_name='Sheet1')\n",
    "data['U238_Pb206'] = 1/data['206/238 2nd Order']\n",
    "data['Pb207_Pb206'] = data['207Pb/206Pb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f77e88e-e630-4e29-859b-ce16dbd0b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants for reducing U-Pb data\n",
    "lambda_238 = 1.55125e-10 #\n",
    "lambda_238err = 1.55125e-10*0.16 #\n",
    "lambda_235 = 9.8485e-10 #\n",
    "lambda_232 = 4.9475e-11 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b4928a6-23a9-44f5-8b90-24576b595a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate initial ages and Stacey-Kramers Common Pb for that age\n",
    "data['206Pb/238U_age_init'] = np.log(data['206/238 2nd Order'] + 1) / lambda_238\n",
    "\n",
    "data['SK207_204'] = 12.998 + 9.74/137.82*(np.exp(lambda_235*3.7e9)-np.exp(lambda_235*data['206Pb/238U_age_init']))\n",
    "data['SK206_204'] = 11.152 + 9.74*(np.exp(lambda_238*3.7e9)-np.exp(lambda_238*data['206Pb/238U_age_init']))\n",
    "data['SK207_206'] = data['SK207_204'] / data['SK206_204']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77ad81d-4d08-4b4f-b727-1cbad99ec445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate initial ages and Stacey-Kramers Common Pb for that age\n",
    "# data['206Pb/238Uc_age_init'] = np.log(data['206/238 2nd Order'] + 1) / lambda_238\n",
    "\n",
    "# data['SK207_204'] = 12.998 + 9.74/137.82*(np.exp(lambda_235*3.7e9)-np.exp(lambda_235*data['206Pb/238Uc_age_init']))\n",
    "# data['SK206_204'] = 11.152 + 9.74*(np.exp(lambda_238*3.7e9)-np.exp(lambda_238*data['206Pb/238Uc_age_init']))\n",
    "# # data['SK208_204'] = 31.230 + 37.4*(np.exp(lambda_232*3.7e9)-np.exp(lambda_232*data['206Pb/238Uc_age_init']))\n",
    "\n",
    "# # data['SK_slope_calc'] = (data['SK207_204'] - 12.998) / (data['SK206_204'] - 11.152)\n",
    "\n",
    "# # data['counts_pb206'] = data['238U'] * data['206/238 2nd Order']\n",
    "# data['SK207_206'] = data['SK207_204'] / data['SK206_204']\n",
    "# # data['U238_Pb206c'] = 1 / data['206Pb/238Uc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b2ffc0f-7742-476f-baa5-8c7126239e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = data.groupby(['SampleLabel'])\n",
    "# samples.get_group('MADER') # put this in selector to go sample by sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1c0a6a4-8bf1-4861-9099-01268097d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function block\n",
    "\n",
    "# # this needs to be a function that receives the selected sample\n",
    "# def get_data_TW_regressions(df,select_regression):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     if select_regression == '1st Order':\n",
    "#         data['U238_Pb206'] = 1/data['206/238 1st Order']\n",
    "#         data['206Pb/238U_age_init'] = np.log(data['206/238 1st Order'] + 1) / lambda_238\n",
    "#         data['SK207_204'] = 12.998 + 9.74/137.82*(np.exp(lambda_235*3.7e9)-np.exp(lambda_235*data['206Pb/238U_age_init']))\n",
    "#         data['SK206_204'] = 11.152 + 9.74*(np.exp(lambda_238*3.7e9)-np.exp(lambda_238*data['206Pb/238U_age_init']))\n",
    "#         data['SK207_206'] = data['SK207_204'] / data['SK206_204']\n",
    "#         pts_x = np.array([df.U238_Pb206,np.zeros_like(df['SK207_206'])]).T\n",
    "#         pts_y = np.array([df['207Pb/206Pb'],df['SK207_206']]).T\n",
    "#         discordia_t = np.zeros((len(df),2))\n",
    "\n",
    "#         for i in range(0,len(df)):\n",
    "#             discordia_t[i] = np.poly1d(np.polyfit(pts_x[i],pts_y[i],1))\n",
    "#     elif select_regression == '2nd Order':\n",
    "#         data['U238_Pb206'] = 1/data['206/238 2nd Order']\n",
    "#         data['206Pb/238U_age_init'] = np.log(data['206/238 2nd Order'] + 1) / lambda_238\n",
    "#         data['SK207_204'] = 12.998 + 9.74/137.82*(np.exp(lambda_235*3.7e9)-np.exp(lambda_235*data['206Pb/238U_age_init']))\n",
    "#         data['SK206_204'] = 11.152 + 9.74*(np.exp(lambda_238*3.7e9)-np.exp(lambda_238*data['206Pb/238U_age_init']))\n",
    "#         data['SK207_206'] = data['SK207_204'] / data['SK206_204']\n",
    "#         pts_x = np.array([df.U238_Pb206,np.zeros_like(df['SK207_206'])]).T\n",
    "#         pts_y = np.array([df['207Pb/206Pb'],df['SK207_206']]).T\n",
    "#         discordia_t = np.zeros((len(df),2))\n",
    "\n",
    "#         for i in range(0,len(df)):\n",
    "#             discordia_t[i] = np.poly1d(np.polyfit(pts_x[i],pts_y[i],1))\n",
    "\n",
    "#     return discordia_t\n",
    "\n",
    "\n",
    "\n",
    "# def get_TW_concordia():\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     # calculate T-W discordia - put in plot function\n",
    "#     t = np.linspace(1,4.6e9,100000)\n",
    "#     pb207_206 = np.zeros(len(t))\n",
    "#     pb206 = np.zeros(len(t))\n",
    "#     u238_pb206 = np.zeros(len(t))\n",
    "#     pb207_206r = np.zeros(len(t))\n",
    "#     for i in range(0,len(t)):\n",
    "#         u238_pb206[i] = 1/(np.exp(lambda_238*t[i])-1)\n",
    "#         pb207_206r[i] = (1/137.88) * ((np.exp(lambda_235*t[i])-1) / (np.exp(lambda_238*t[i])-1))\n",
    "        \n",
    "#     return u238_pb206,pb207_206r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def get_projections(df,select_regression):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     # get the TW concordia values\n",
    "#     x_TW,y_TW = get_TW_concordia()\n",
    "#     discorida_regressions = get_data_TW_regressions(df,select_regression) # get regressions\n",
    "#     # array of xvalues to project over\n",
    "#     x_vals = np.linspace(min(x_TW),max(x_TW),100000)\n",
    "#     # pts_pb_r = [] # set up array to be filled with calculated radiogenic lead component\n",
    "#     pts_pb_r = np.zeros(len(discorida_regressions))\n",
    "#     concordia_238_206 = np.zeros(len(discorida_regressions))\n",
    "\n",
    "#     for i in range(0,len(discorida_regressions)):\n",
    "\n",
    "#         discordia_207206 = discorida_regressions[i][0]*x_vals+discorida_regressions[i][1]\n",
    "#         discordia_238206 = (discordia_207206-discorida_regressions[i][1])/discorida_regressions[i][0]\n",
    "\n",
    "#         delta_y = (discorida_regressions[i][1] + x_TW * discorida_regressions[i][0]) - y_TW # distance of y value from line\n",
    "#         indx = np.where(delta_y[1:]*delta_y[:-1]<0)[0] # index the regression for where the curve cross the regression\n",
    "#         d_ratio = delta_y[indx] / (delta_y[indx] - delta_y[indx + 1]) # similar triangles geometry gets points\n",
    "#         points = np.zeros((len(indx), 2)) # empty array for crossing points\n",
    "#         points[:,0] = x_TW[indx] + d_ratio * (x_TW[indx+1] - x_TW[indx]) # x crossings\n",
    "#         points[:,1] = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "#         y_point = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "#         x_point = x_TW[indx] + d_ratio * (x_TW[indx+1] - x_TW[indx]) # x crossings\n",
    "        \n",
    "#         if len(y_point) >= 1:\n",
    "#             pts_pb_r[i] = min(y_point)\n",
    "#         elif len(y_point) < 0:\n",
    "#             pts_pb_r[i] = 0\n",
    "            \n",
    "#         # need to work this out to get concordia points, then use these to calculate ages, store other ages as well.\n",
    "#         # may need to fuck with delta_y and make a delta_x, etc\n",
    "#         if len(x_point) > 1:\n",
    "#             concordia_238_206[i] = min(x_point)\n",
    "#         elif len(x_point) == 1:\n",
    "#             concordia_238_206[i] = x_point\n",
    "    \n",
    "#     return points,concordia_238_206,pts_pb_r,discordia_207206,discordia_238206\n",
    "\n",
    "    \n",
    "\n",
    "# def plot_TW(df,xlim_start,xlim_stop,ylim_start,ylim_stop,select_regression):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     plt.style.use('seaborn-colorblind')\n",
    "#     # fig = Figure(figsize=(4,7))\n",
    "#     fig = Figure()\n",
    "#     ax = fig.add_subplot()\n",
    "    \n",
    "#     x_TW,y_TW = get_TW_concordia()\n",
    "    \n",
    "#     disc_regressions = get_data_TW_regressions(df,select_regression)\n",
    "    \n",
    "#     x_vals = np.linspace(min(x_TW),max(x_TW),100000)\n",
    "#     pts_pb_r = np.zeros(len(disc_regressions))\n",
    "    \n",
    "#     for i in range(0,len(disc_regressions)):\n",
    "#         # points,pts_pb_r,discordia_207206,discordia_238206 = get_projections(df)\n",
    "#         discordia_207206 = disc_regressions[i][0]*x_vals+disc_regressions[i][1]\n",
    "#         discordia_238206 = (discordia_207206-disc_regressions[i][1])/disc_regressions[i][0]\n",
    "\n",
    "#         delta_y = (disc_regressions[i][1] + x_TW * disc_regressions[i][0]) - y_TW # distance of y value from line\n",
    "#         indx = np.where(delta_y[1:]*delta_y[:-1]<0)[0] # index the regression for where the curve cross the regression\n",
    "#         d_ratio = delta_y[indx] / (delta_y[indx] - delta_y[indx + 1]) # similar triangles geometry gets points\n",
    "#         points = np.zeros((len(indx), 2)) # empty array for crossing points\n",
    "#         points[:,0] = x_TW[indx] + d_ratio * (x_TW[indx+1] - x_TW[indx]) # x crossings\n",
    "#         points[:,1] = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "#         y_point = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "#         if len(y_point) >= 1:\n",
    "#             pts_pb_r[i] = min(y_point)\n",
    "#         elif len(y_point) < 0:\n",
    "#             pts_pb_r[i] = 0\n",
    "            \n",
    "#         ax.plot(discordia_238206,discordia_207206,'-k',lw=0.5)\n",
    "#         ax.plot(points[:,0],points[:,1],'og',lw=1,mec='k')\n",
    "        \n",
    "#     ax.plot(df.U238_Pb206,df.Pb207_Pb206,'kd')\n",
    "#     if select_regression == '1st Order':\n",
    "#         ax.errorbar(df.U238_Pb206,df.Pb207_Pb206,df['206/238 1st Order'],df['207Pb/206Pb'],fmt='none',ecolor='k',elinewidth=0.5)\n",
    "#     elif select_regression == '2nd Order':\n",
    "#         ax.errorbar(df.U238_Pb206,df.Pb207_Pb206,df['206/238 2nd Order'],df['207Pb/206Pb'],fmt='none',ecolor='k',elinewidth=0.5)\n",
    "#     else:\n",
    "#         pass\n",
    "#     ax.plot(x_TW,y_TW,'k',lw=1)\n",
    "#     # ax.legend(loc='upper right',fontsize=8)\n",
    "#     ax.set_xlabel('$^{238}$U / $^{206}$Pb$^{*}$',fontsize=8)\n",
    "#     ax.set_ylabel('[$^{207}$Pb / $^{206}$Pb]$^{*}$',fontsize=8)\n",
    "#     ax.set_ylim(ylim_start,ylim_stop)\n",
    "#     ax.set_xlim(x_vals[0],xlim_stop)\n",
    "#     return fig\n",
    "\n",
    "\n",
    "\n",
    "# def correct_standard_ages(df,select_regression):\n",
    "#     \"\"\"\n",
    "#     function to calculate Pb and fractionation factor corrected ages\n",
    "#     \"\"\"\n",
    "#     # get points needed for correction\n",
    "#     points,concordia_238_206,pts_pb_r,na,naII = get_projections(df,select_regression)\n",
    "    \n",
    "#     # set up empty arrays to be filled for common lead corrections\n",
    "#     common_filter = []\n",
    "#     f_filter = []\n",
    "    \n",
    "#     pb_m = df['207Pb/206Pb'] # measured 207/206\n",
    "#     common = df['SK207_206']\n",
    "    \n",
    "#     for i in common:\n",
    "#         if i <= 0:\n",
    "#             common_filter.append(0)\n",
    "#         else:\n",
    "#             common_filter.append(i)\n",
    "    \n",
    "#     # calculate fraction of common Pb\n",
    "#     f_ = (pb_m - pts_pb_r) / (common - pts_pb_r)\n",
    "#     # set up array to set f = 0 if point lies on or below Concordia (i.e., no common Pb present)\n",
    "#     f = []\n",
    "    \n",
    "#     for k,j in zip(common_filter,f_):\n",
    "#         if k <= 0:\n",
    "#             f.append(0)\n",
    "#         elif j < 0:\n",
    "#             f.append(0)\n",
    "#         else:\n",
    "#             f.append(j)\n",
    "            \n",
    "#     # append the calculations to the sample dataframe\n",
    "#     df['207Pb/206Pbr'] = pts_pb_r\n",
    "#     # df['207Pb/206Pbcommon'] = common_filter\n",
    "#     df['f'] = f\n",
    "    \n",
    "#     df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
    "#     df['206Pb/238Upb'] = 1/concordia_238_206\n",
    "#     df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
    "    \n",
    "#     avg_std_age = df['206Pb/238U_age'].mean()\n",
    "#     if select_regression == '1st Order':\n",
    "#         avg_reg_err = df['SE 206/238 1st Order'].mean()\n",
    "#     elif select_regression == '2nd Order':\n",
    "#         avg_reg_err = df['SE 206/238 2nd Order'].mean()\n",
    "#     else:\n",
    "#         pass\n",
    "    \n",
    "#     return avg_std_age,avg_reg_err\n",
    "    \n",
    "    \n",
    "\n",
    "# def correct_sample_ages(df,std,std_txt,select_regression):\n",
    "#     \"\"\"\n",
    "#     function to calculate Pb and fractionation factor corrected ages\n",
    "#     \"\"\"\n",
    "#     # df = df.reset_index()\n",
    "#     # get points needed for correction\n",
    "#     points,concordia_238_206,pts_pb_r,n,a = get_projections(df,select_regression)\n",
    "    \n",
    "#     # set up empty arrays to be filled for common lead corrections\n",
    "#     common_filter = []\n",
    "#     f_filter = []\n",
    "    \n",
    "#     pb_m = df['207Pb/206Pb'] # measured 207/206\n",
    "#     common = df['SK207_206']\n",
    "    \n",
    "#     for i in common:\n",
    "#         if i <= 0:\n",
    "#             common_filter.append(0)\n",
    "#         else:\n",
    "#             common_filter.append(i)\n",
    "    \n",
    "#     # calculate fraction of common Pb\n",
    "#     f_ = (pb_m - pts_pb_r) / (common - pts_pb_r)\n",
    "#     # set up array to set f = 0 if point lies on or below Concordia (i.e., no common Pb present)\n",
    "#     f = []\n",
    "    \n",
    "#     for k,j in zip(common_filter,f_):\n",
    "#         if k <= 0:\n",
    "#             f.append(0)\n",
    "#         elif j < 0:\n",
    "#             f.append(0)\n",
    "#         else:\n",
    "#             f.append(j)\n",
    "            \n",
    "#     # append the calculations to the sample dataframe\n",
    "#     df['207Pb/206Pbr'] = pts_pb_r\n",
    "#     # df['207Pb/206Pbcommon'] = common_filter\n",
    "#     df['f'] = f\n",
    "    \n",
    "#     df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
    "#     # df['206Pb/238Upbc'] = df.counts_pb206r/df['238U']\n",
    "#     df['206Pb/238Upb'] = 1/concordia_238_206\n",
    "#     df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
    "\n",
    "    \n",
    "#     # will need input for which standard to use now! standard will need to be calculated by a separate function and called/input here.\n",
    "#     frac_factor,tims_age,tims_error,std_avg,std_avgerr = get_standard_fracfctr(std,std_txt)\n",
    "#     df['206Pb/238U_correctedage'] = df['206Pb/238Uc_age']*frac_factor\n",
    "    \n",
    "#     #propagate errors\n",
    "#     #error on fractionation factor. includes error from ID-TIMS and ICPMS\n",
    "#     dfrac = np.abs(frac_factor)*((1/tims_age)**2*tims_error**2 + (1/std_avg)**2*std_avgerr**2)**(1/2)\n",
    "#     #error on age equation. error on decay constant includes 1.5* counting stats (Mattinson 1987)\n",
    "#     if select_regression == '1st Order':\n",
    "#         dage = np.abs(df['206Pb/238U_age'])*((1/df['206/238 1st Order'])**2*df['SE 206/238 1st Order']**2 + (0.16/100)**2 + (1/frac_factor)**2*dfrac**2)**(1/2)\n",
    "#     elif select_regression == '2nd Order':\n",
    "#         dage = np.abs(df['206Pb/238U_age'])*((1/df['206/238 2nd Order'])**2*df['SE 206/238 2nd Order']**2 + (0.16/100)**2 + (1/frac_factor)**2*dfrac**2)**(1/2)\n",
    "#     else:\n",
    "#         pass\n",
    "#     #error on estimation for common lead using 207 method. Uses conservaitve estimates of 1.0 for 206/204 and 0.3 for 207/204 (Mattionson, 1987)\n",
    "#     dinit = np.abs(common)*((1/df['SK207_204'])**2*0.3**2 + (1/df['SK206_204'])**2*1**2)**(1/2)\n",
    "#     # total propagated error\n",
    "#     dagetot = (dage**2 +  df['SE 206/204']**2 + dinit**2)**(1/2)\n",
    "    \n",
    "#     df['∆206/238 age (meas.)'] = dage\n",
    "#     df['∆206/238 age (tot.)'] = dagetot\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def get_standard_fracfctr(std,std_txt,select_regression):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     # selected_std = samples.get_group(std)\n",
    "    \n",
    "#     accepted_ages = {\n",
    "#         'Temora':416780000,\n",
    "#         'FishCanyon': 28478000,\n",
    "#         '94_35': 55500000,\n",
    "#         'Plesovice': 337100000,\n",
    "#         'R33': 419300000,\n",
    "#         '91500': 1062400000,\n",
    "#         'FC1': 1099500000,\n",
    "#         'Oracle': 1436200000,\n",
    "#         'Tan-Bra': 2507800000,\n",
    "#         'OG1': 3440700000\n",
    "#     }\n",
    "    \n",
    "#     TIMS_errors = {\n",
    "#         'Temora':330000,\n",
    "#         'FishCanyon': 24000,\n",
    "#         '94_35': 80000,\n",
    "#         'Plesovice': 200000,\n",
    "#         'R33': 400000,\n",
    "#         '91500': 1900000,\n",
    "#         'FC1': 330000,\n",
    "#         'Oracle': 1300000,\n",
    "#         'Tan-Bra': 1500000,\n",
    "#         'OG1': 3200000\n",
    "#     }\n",
    "    \n",
    "#     std_avg,std_avgerr = correct_standard_ages(std,select_regression)\n",
    "#     frac_factor = accepted_ages.get(std_txt)/std_avg\n",
    "#     tims_age = accepted_ages.get(std_txt)\n",
    "#     tims_error = TIMS_errors.get(std_txt)\n",
    "    \n",
    "#     return frac_factor,tims_age,tims_error,std_avg,std_avgerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "257f4e9a-eef3-471f-8988-98bea5483ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function block\n",
    "\n",
    "# this needs to be a function that receives the selected sample\n",
    "def get_data_TW_regressions(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    pts_x = np.array([df.U238_Pb206,np.zeros_like(df['SK207_206'])]).T\n",
    "    pts_y = np.array([df['207Pb/206Pb'],df['SK207_206']]).T\n",
    "    discordia_t = np.zeros((len(df),2))\n",
    "\n",
    "    for i in range(0,len(df)):\n",
    "        discordia_t[i] = np.poly1d(np.polyfit(pts_x[i],pts_y[i],1))\n",
    "\n",
    "    return discordia_t\n",
    "\n",
    "\n",
    "\n",
    "def get_TW_concordia():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # calculate T-W discordia - put in plot function\n",
    "    t = np.linspace(1,4.6e9,100000)\n",
    "    pb207_206 = np.zeros(len(t))\n",
    "    pb206 = np.zeros(len(t))\n",
    "    u238_pb206 = np.zeros(len(t))\n",
    "    pb207_206r = np.zeros(len(t))\n",
    "    for i in range(0,len(t)):\n",
    "        u238_pb206[i] = 1/(np.exp(lambda_238*t[i])-1)\n",
    "        pb207_206r[i] = (1/137.88) * ((np.exp(lambda_235*t[i])-1) / (np.exp(lambda_238*t[i])-1))\n",
    "        \n",
    "    return u238_pb206,pb207_206r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_projections(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # get the TW concordia values\n",
    "    x_TW,y_TW = get_TW_concordia()\n",
    "    discorida_regressions = get_data_TW_regressions(df) # get regressions\n",
    "    # array of xvalues to project over\n",
    "    x_vals = np.linspace(min(x_TW),max(x_TW),100000)\n",
    "    # pts_pb_r = [] # set up array to be filled with calculated radiogenic lead component\n",
    "    pts_pb_r = np.zeros(len(discorida_regressions))\n",
    "    concordia_238_206 = np.zeros(len(discorida_regressions))\n",
    "\n",
    "    for i in range(0,len(discorida_regressions)):\n",
    "\n",
    "        discordia_207206 = discorida_regressions[i][0]*x_vals+discorida_regressions[i][1]\n",
    "        discordia_238206 = (discordia_207206-discorida_regressions[i][1])/discorida_regressions[i][0]\n",
    "\n",
    "        delta_y = (discorida_regressions[i][1] + x_TW * discorida_regressions[i][0]) - y_TW # distance of y value from line\n",
    "        indx = np.where(delta_y[1:]*delta_y[:-1]<0)[0] # index the regression for where the curve cross the regression\n",
    "        d_ratio = delta_y[indx] / (delta_y[indx] - delta_y[indx + 1]) # similar triangles geometry gets points\n",
    "        points = np.zeros((len(indx), 2)) # empty array for crossing points\n",
    "        points[:,0] = x_TW[indx] + d_ratio * (x_TW[indx+1] - x_TW[indx]) # x crossings\n",
    "        points[:,1] = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "        y_point = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "        x_point = x_TW[indx] + d_ratio * (x_TW[indx+1] - x_TW[indx]) # x crossings\n",
    "        \n",
    "        if len(y_point) >= 1:\n",
    "            pts_pb_r[i] = min(y_point)\n",
    "        elif len(y_point) < 0:\n",
    "            pts_pb_r[i] = 0\n",
    "            \n",
    "        # need to work this out to get concordia points, then use these to calculate ages, store other ages as well.\n",
    "        # may need to fuck with delta_y and make a delta_x, etc\n",
    "        if len(x_point) > 1:\n",
    "            concordia_238_206[i] = min(x_point)\n",
    "        elif len(x_point) == 1:\n",
    "            concordia_238_206[i] = x_point\n",
    "    \n",
    "    return points,concordia_238_206,pts_pb_r,discordia_207206,discordia_238206\n",
    "\n",
    "    \n",
    "\n",
    "def plot_TW(df,xlim_start,xlim_stop,ylim_start,ylim_stop):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-colorblind')\n",
    "    # fig = Figure(figsize=(4,7))\n",
    "    fig = Figure()\n",
    "    ax = fig.add_subplot()\n",
    "    \n",
    "    x_TW,y_TW = get_TW_concordia()\n",
    "    \n",
    "    disc_regressions = get_data_TW_regressions(df)\n",
    "    \n",
    "    x_vals = np.linspace(min(x_TW),max(x_TW),100000)\n",
    "    pts_pb_r = np.zeros(len(disc_regressions))\n",
    "    \n",
    "    for i in range(0,len(disc_regressions)):\n",
    "        # points,pts_pb_r,discordia_207206,discordia_238206 = get_projections(df)\n",
    "        discordia_207206 = disc_regressions[i][0]*x_vals+disc_regressions[i][1]\n",
    "        discordia_238206 = (discordia_207206-disc_regressions[i][1])/disc_regressions[i][0]\n",
    "\n",
    "        delta_y = (disc_regressions[i][1] + x_TW * disc_regressions[i][0]) - y_TW # distance of y value from line\n",
    "        indx = np.where(delta_y[1:]*delta_y[:-1]<0)[0] # index the regression for where the curve cross the regression\n",
    "        d_ratio = delta_y[indx] / (delta_y[indx] - delta_y[indx + 1]) # similar triangles geometry gets points\n",
    "        points = np.zeros((len(indx), 2)) # empty array for crossing points\n",
    "        points[:,0] = x_TW[indx] + d_ratio * (x_TW[indx+1] - x_TW[indx]) # x crossings\n",
    "        points[:,1] = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "        y_point = y_TW[indx] + d_ratio * (y_TW[indx+1] - y_TW[indx]) # y crossings\n",
    "        if len(y_point) >= 1:\n",
    "            pts_pb_r[i] = min(y_point)\n",
    "        elif len(y_point) < 0:\n",
    "            pts_pb_r[i] = 0\n",
    "            \n",
    "        ax.plot(discordia_238206,discordia_207206,'-k',lw=0.5)\n",
    "        ax.plot(points[:,0],points[:,1],'og',lw=1,mec='k')\n",
    "        \n",
    "    ax.plot(df.U238_Pb206,df.Pb207_Pb206,'kd')\n",
    "    ax.errorbar(df.U238_Pb206,df.Pb207_Pb206,df['206/238 2nd Order'],df['207Pb/206Pb'],fmt='none',ecolor='k',elinewidth=0.5)\n",
    "    ax.plot(x_TW,y_TW,'k',lw=1)\n",
    "    # ax.legend(loc='upper right',fontsize=8)\n",
    "    ax.set_xlabel('$^{238}$U / $^{206}$Pb$^{*}$',fontsize=8)\n",
    "    ax.set_ylabel('[$^{207}$Pb / $^{206}$Pb]$^{*}$',fontsize=8)\n",
    "    ax.set_ylim(ylim_start,ylim_stop)\n",
    "    ax.set_xlim(x_vals[0],xlim_stop)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def correct_standard_ages(df):\n",
    "    \"\"\"\n",
    "    function to calculate Pb and fractionation factor corrected ages\n",
    "    \"\"\"\n",
    "    # get points needed for correction\n",
    "    points,concordia_238_206,pts_pb_r,na,naII = get_projections(df)\n",
    "    \n",
    "    # set up empty arrays to be filled for common lead corrections\n",
    "    common_filter = []\n",
    "    f_filter = []\n",
    "    \n",
    "    pb_m = df['207Pb/206Pb'] # measured 207/206\n",
    "    common = df['SK207_206']\n",
    "    \n",
    "    for i in common:\n",
    "        if i <= 0:\n",
    "            common_filter.append(0)\n",
    "        else:\n",
    "            common_filter.append(i)\n",
    "    \n",
    "    # calculate fraction of common Pb\n",
    "    f_ = (pb_m - pts_pb_r) / (common - pts_pb_r)\n",
    "    # set up array to set f = 0 if point lies on or below Concordia (i.e., no common Pb present)\n",
    "    f = []\n",
    "    \n",
    "    for k,j in zip(common_filter,f_):\n",
    "        if k <= 0:\n",
    "            f.append(0)\n",
    "        elif j < 0:\n",
    "            f.append(0)\n",
    "        else:\n",
    "            f.append(j)\n",
    "            \n",
    "    # append the calculations to the sample dataframe\n",
    "    df['207Pb/206Pbr'] = pts_pb_r\n",
    "    # df['207Pb/206Pbcommon'] = common_filter\n",
    "    df['f'] = f\n",
    "    \n",
    "    df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
    "    df['206Pb/238Upb'] = 1/concordia_238_206\n",
    "    df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
    "    \n",
    "    avg_std_age = df['206Pb/238U_age'].mean()\n",
    "    avg_reg_err = df['SE 206/238 2nd Order'].mean()\n",
    "    \n",
    "    return avg_std_age,avg_reg_err\n",
    "    \n",
    "    \n",
    "\n",
    "def correct_sample_ages(df,std,std_txt):\n",
    "    \"\"\"\n",
    "    function to calculate Pb and fractionation factor corrected ages\n",
    "    \"\"\"\n",
    "    # df = df.reset_index()\n",
    "    # get points needed for correction\n",
    "    points,concordia_238_206,pts_pb_r,n,a = get_projections(df)\n",
    "    \n",
    "    # set up empty arrays to be filled for common lead corrections\n",
    "    common_filter = []\n",
    "    f_filter = []\n",
    "    \n",
    "    pb_m = df['207Pb/206Pb'] # measured 207/206\n",
    "    common = df['SK207_206']\n",
    "    \n",
    "    for i in common:\n",
    "        if i <= 0:\n",
    "            common_filter.append(0)\n",
    "        else:\n",
    "            common_filter.append(i)\n",
    "    \n",
    "    # calculate fraction of common Pb\n",
    "    f_ = (pb_m - pts_pb_r) / (common - pts_pb_r)\n",
    "    # set up array to set f = 0 if point lies on or below Concordia (i.e., no common Pb present)\n",
    "    f = []\n",
    "    \n",
    "    for k,j in zip(common_filter,f_):\n",
    "        if k <= 0:\n",
    "            f.append(0)\n",
    "        elif j < 0:\n",
    "            f.append(0)\n",
    "        else:\n",
    "            f.append(j)\n",
    "            \n",
    "    # append the calculations to the sample dataframe\n",
    "    df['207Pb/206Pbr'] = pts_pb_r\n",
    "    # df['207Pb/206Pbcommon'] = common_filter\n",
    "    df['f'] = f\n",
    "    \n",
    "    df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
    "    # df['206Pb/238Upbc'] = df.counts_pb206r/df['238U']\n",
    "    df['206Pb/238Upb'] = 1/concordia_238_206\n",
    "    df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
    "\n",
    "    \n",
    "    # will need input for which standard to use now! standard will need to be calculated by a separate function and called/input here.\n",
    "    frac_factor,tims_age,tims_error,std_avg,std_avgerr = get_standard_fracfctr(std,std_txt)\n",
    "    df['206Pb/238U_correctedage'] = df['206Pb/238U_age']*frac_factor\n",
    "    \n",
    "    #propagate errors\n",
    "    #error on fractionation factor. includes error from ID-TIMS and ICPMS\n",
    "    dfrac = np.abs(frac_factor)*((1/tims_age)**2*tims_error**2 + (1/std_avg)**2*std_avgerr**2)**(1/2)\n",
    "    #error on age equation. error on decay constant includes 1.5* counting stats (Mattinson 1987)\n",
    "    dage = np.abs(df['206Pb/238U_age'])*((1/df['206/238 2nd Order'])**2*df['SE 206/238 2nd Order']**2 + (0.16/100)**2 + (1/frac_factor)**2*dfrac**2)**(1/2)\n",
    "    #error on estimation for common lead using 207 method. Uses conservaitve estimates of 1.0 for 206/204 and 0.3 for 207/204 (Mattionson, 1987)\n",
    "    dinit = np.abs(common)*((1/df['SK207_204'])**2*0.3**2 + (1/df['SK206_204'])**2*1**2)**(1/2)\n",
    "    # total propagated error\n",
    "    dagetot = (dage**2 +  df['SE 206/204']**2 + dinit**2)**(1/2)\n",
    "    \n",
    "    df['∆206/238 age (meas.)'] = dage\n",
    "    df['∆206/238 age (tot.)'] = dagetot\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_standard_fracfctr(std,std_txt):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # selected_std = samples.get_group(std)\n",
    "    \n",
    "    accepted_ages = {\n",
    "        'Temora':416780000,\n",
    "        'FishCanyon': 28478000,\n",
    "        '94_35': 55500000,\n",
    "        'Plesovice': 337100000,\n",
    "        'R33': 419300000,\n",
    "        '91500': 1062400000,\n",
    "        'FC1': 1099500000,\n",
    "        'Oracle': 1436200000,\n",
    "        'Tan-Bra': 2507800000,\n",
    "        'OG1': 3440700000\n",
    "    }\n",
    "    \n",
    "    TIMS_errors = {\n",
    "        'Temora':330000,\n",
    "        'FishCanyon': 24000,\n",
    "        '94_35': 80000,\n",
    "        'Plesovice': 200000,\n",
    "        'R33': 400000,\n",
    "        '91500': 1900000,\n",
    "        'FC1': 330000,\n",
    "        'Oracle': 1300000,\n",
    "        'Tan-Bra': 1500000,\n",
    "        'OG1': 3200000\n",
    "    }\n",
    "    \n",
    "    std_avg,std_avgerr = correct_standard_ages(std)\n",
    "    frac_factor = accepted_ages.get(std_txt)/std_avg\n",
    "    tims_age = accepted_ages.get(std_txt)\n",
    "    tims_error = TIMS_errors.get(std_txt)\n",
    "    \n",
    "    return frac_factor,tims_age,tims_error,std_avg,std_avgerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3927ea7-851c-4dce-b47e-309564317e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class finalize_ages(param.Parameterized):\n",
    "    \n",
    "    # set up parameters. those with the suffix _pass are set up in order to be updated in the first callback below.\n",
    "    input_data = param.DataFrame(default=data,precedence=-1) # wont need output since writing back to df?\n",
    "    blank_output = pd.DataFrame([np.zeros(len(data.columns))],columns=list(data.columns))\n",
    "    output_data = param.DataFrame(default=blank_output,precedence=-0.2)\n",
    "    x_axis_TW = param.Range(default=(1,100),bounds=(0,4000)) # for x-axis\n",
    "    y_axis_TW = param.Range(default=(0,1),bounds=(0,3)) # for y-axis\n",
    "    text_sample_selector = param.String(default='Input Sample ID')# for getting samples. need to split to get all of given name... or have them do text input\n",
    "    text_standard_selector = param.String(default='Input Standard ID')# for getting samples. need to split to get all of given name... or have them do text input\n",
    "    update_output_button = param.Action(lambda x: x.add_output_data(),label='Approve Data')\n",
    "    export_data_button = param.Action(lambda x: x.export_data(),label='DDDT!')\n",
    "    select_regression = param.ObjectSelector(default='1st Order', objects=['1st Order','2nd Order'])\n",
    "    \n",
    "    def __init__(self,**params):\n",
    "        super().__init__(**params)\n",
    "        self.input_data_widget = pn.Param(self.param.input_data),\n",
    "        self.output_data_widget = pn.Param(self.param.output_data),\n",
    "        self.widgets = pn.Param(self,parameters=['x_axis_TW','y_axis_TW','text_standard_selector','update_output_button','export_data_button'])\n",
    "        # may need to put in another widgets param\n",
    "        # self._layout = pn.Row(\n",
    "        #     pn.Param(self,parameters=['update_output_button','sample_subset','ablation_slider','background_slider','ablation_plot_ylim_slider',\n",
    "        #                               'ratio_plot_ylim_slider',\n",
    "        #                               ]\n",
    "        #             ),\n",
    "        #     pn.Param(widgets={'ratio_buttons': pn.widgets.CheckBoxGroup, 'regression_buttons': pn.widgets.CheckBoxGroup,\n",
    "        #                      'export_data_button': pn.widgets.CheckBoxGroup(name='DDDT',button_type='success')}),\n",
    "        #     self.input_data_widget,\n",
    "        #     self.output_data_widget,\n",
    "        #     width=1,\n",
    "        #     sizing_mode='fixed'\n",
    "        # )\n",
    "        \n",
    "    @pn.depends('output_data',watch=True)\n",
    "    def _update_data_widget(self):\n",
    "        self.output_data_widget = self.output_data\n",
    "        self.output_data_widget.height = 40\n",
    "        self.output_data_widget.heightpolicy = 'Fixed'\n",
    "        return pn.widgets.Tabulator(self.output_data_widget,width=200)\n",
    "        \n",
    "    @pn.depends('input_data','text_sample_selector','x_axis_TW','y_axis_TW','select_regression')\n",
    "    def call_TW(self):\n",
    "        # if self.text_sample_selector is not 'Input Sample ID':\n",
    "        data_toplot = self.input_data[self.input_data['SampleLabel'].str.contains(self.text_sample_selector)]\n",
    "        return plot_TW(data_toplot,self.x_axis_TW[0],self.x_axis_TW[1],self.y_axis_TW[0],self.y_axis_TW[1])\n",
    "    \n",
    "    # @pn.depends('input_data','text_sample_selector','text_standard_selector')\n",
    "    def add_output_data(self,event=None):\n",
    "        #need to add columns to input data somewhere else\n",
    "        data_to_update = self.input_data[self.input_data['SampleLabel'].str.contains(self.text_sample_selector)]\n",
    "        chosen_std = self.input_data[self.input_data['SampleLabel'].str.contains(self.text_standard_selector)]\n",
    "        ages = correct_sample_ages(data_to_update,chosen_std,self.text_standard_selector)\n",
    "        if self.output_data is None:\n",
    "            self.output_data = ages\n",
    "        else:\n",
    "            self.output_data = self.output_data.append(ages,ignore_index=True)\n",
    "        # self.input_data = self.input_data.update(ages) # will need to create blank columns on inputdata\n",
    "        # self.input_data = ages # will need to create blank columns on inputdata\n",
    "        \n",
    "    @pn.depends('output_data')\n",
    "    def export_data(self,event=None):\n",
    "        self.output_data.to_excel('output_lasertramZ_ages.xlsx')\n",
    "\n",
    "reduce_ages = finalize_ages(name='Reduce Ages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "820d06f3-fcd3-4d92-8054-2e03b4aca020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"tabulator\"], function(Tabulator) {\n",
       "\twindow.Tabulator = Tabulator\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"moment\"], function(moment) {\n",
       "\twindow.moment = moment\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 4;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js\", \"https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/css/tabulator_simple.min.css\", \"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.css\", \"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/debugger.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/dataframe.css\"];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n",
       "    },    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 4;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js\", \"https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.js\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/css/tabulator_simple.min.css\", \"https://cdn.jsdelivr.net/npm/notyf@3/notyf.min.css\", \"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/debugger.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/widgets.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.13.1/dist/css/dataframe.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.ParamMethod00298: The method supplied for Panel to display was declared with `watch=True`, which will cause the method to be called twice for any change in a dependent Parameter. `watch` should be False when Panel is responsible for displaying the result of the method call, while `watch=True` should be reserved for methods that work via side-effects, e.g. by modifying internal state of a class or global state in an application's namespace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:57607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x7f78b18d6e20>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tornado.access:404 GET /favicon.ico (::1) 1.69ms\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['207Pb/206Pbr'] = pts_pb_r\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['f'] = f\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:215: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238Upb'] = 1/concordia_238_206\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['207Pb/206Pbr'] = pts_pb_r\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['f'] = f\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238Upb'] = 1/concordia_238_206\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238U_correctedage'] = df['206Pb/238U_age']*frac_factor\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['∆206/238 age (meas.)'] = dage\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['∆206/238 age (tot.)'] = dagetot\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/2230271476.py:56: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.output_data = self.output_data.append(ages,ignore_index=True)\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['207Pb/206Pbr'] = pts_pb_r\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['f'] = f\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:215: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238Upb'] = 1/concordia_238_206\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:216: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['207Pb/206Pbr'] = pts_pb_r\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['f'] = f\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['counts_pb206r'] = df['206Pb'] * (1-df['f'])\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238Upb'] = 1/concordia_238_206\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238U_age'] = np.log(df['206Pb/238Upb'] + 1) / lambda_238\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['206Pb/238U_correctedage'] = df['206Pb/238U_age']*frac_factor\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['∆206/238 age (meas.)'] = dage\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/1180569260.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['∆206/238 age (tot.)'] = dagetot\n",
      "/var/folders/h0/nxt863516yb3cyz22ybjvvm80000gn/T/ipykernel_40906/2230271476.py:56: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.output_data = self.output_data.append(ages,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "pn.extension()\n",
    "\n",
    "# fixed, stretch_width, stretch_height, stretch_both, scale_width, scale_height, scale_both, None]\n",
    "\n",
    "# app = pn.Row(pn.Column(pn.Row(reduce_ages.call_TW\n",
    "#                              ),\n",
    "#                        pn.Row(reduce_ages._update_data_widget\n",
    "#                              )\n",
    "#                       ),\n",
    "#              pn.Column(pn.Row(pn.WidgetBox(pn.Param(reduce_ages.param))\n",
    "#                              )\n",
    "#                       )\n",
    "#             )\n",
    "width_ratios=[10,5]\n",
    "grid_layout = pn.GridSpec(sizing_mode='scale_both')\n",
    "# grid_layout = pn.GridSpec()\n",
    "\n",
    "grid_layout[0,0] = pn.Column(reduce_ages.call_TW)\n",
    "grid_layout[1,0] = pn.Row(reduce_ages._update_data_widget)\n",
    "\n",
    "grid_layout[0,1] = pn.Row(pn.WidgetBox(pn.Param(reduce_ages.param,\n",
    "                                         # widgets={'regression_buttons': pn.widgets.CheckBoxGroup,\n",
    "                                         #          'ratio_buttons': pn.widgets.CheckBoxGroup,\n",
    "                                         #          'export_data_button': pn.widgets.Button(name='DDDT!',button_type='success')}\n",
    "                                               )\n",
    "                                      )\n",
    "                         )\n",
    "\n",
    "grid_layout.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a60e8-94ea-43fe-b8c4-c75ae2fbcdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d7a1e-bd12-4551-81a3-d6ef566c1fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
